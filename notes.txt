One Epoch of RNN with descemb_bert on mortality
100%|██████████| 3239/3239 [01:15<00:00, 43.06it/s]
[2024-03-27 21:55:18,964][train][INFO] - epoch: 1, loss: 0.605, auroc: 0.442, auprc: 0.064
[2024-03-27 21:55:18,964][trainers.trainer][INFO] - begin validation on 'valid' subset
[2024-03-27 21:55:28,215][valid][INFO] - epoch: 1, loss: 0.556, auroc: 0.430, auprc: 0.064
[2024-03-27 21:55:28,215][trainers.trainer][INFO] - begin validation on 'test' subset
[2024-03-27 21:55:37,493][test][INFO] - epoch: 1, loss: 1.109, auroc: 0.437, auprc: 0.064
[2024-03-27 21:55:37,493][trainers.trainer][INFO] - Saving checkpoint to checkpoints\checkpoint_best.pt
[2024-03-27 21:55:37,548][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints\checkpoint_best.pt
[2024-03-27 21:55:37,548][__main__][INFO] - done training

One Epoch of RNN with codeemb on mortality
[2024-03-27 23:25:41,904][train][INFO] - epoch: 1, loss: 0.590, auroc: 0.442, auprc: 0.063
[2024-03-27 23:25:41,904][trainers.trainer][INFO] - begin validation on 'valid' subset
[2024-03-27 23:25:46,650][valid][INFO] - epoch: 1, loss: 0.542, auroc: 0.429, auprc: 0.065
[2024-03-27 23:25:46,650][trainers.trainer][INFO] - begin validation on 'test' subset
[2024-03-27 23:25:51,334][test][INFO] - epoch: 1, loss: 1.082, auroc: 0.436, auprc: 0.066
[2024-03-27 23:25:51,334][trainers.trainer][INFO] - Saving checkpoint to checkpoints\checkpoint_best.pt
[2024-03-27 23:25:51,343][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints\checkpoint_best.pt
[2024-03-27 23:25:51,343][__main__][INFO] - done training

Vocab Size
MIMIC
NV vocab size :  2762
DSVA vocab size :  28566
VC vocab size :  28566

EICU
NV vocab size :  2100
DSVA vocab size :  130316
VC vocab size :  130316


BertTextEncoder(
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 128, padding_idx=0)
      (position_embeddings): Embedding(512, 128)
      (token_type_embeddings): Embedding(2, 128)
      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-1): 2 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=128, out_features=128, bias=True)
              (key): Linear(in_features=128, out_features=128, bias=True)
              (value): Linear(in_features=128, out_features=128, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=128, out_features=128, bias=True)
              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=128, out_features=512, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=512, out_features=128, bias=True)
            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=128, out_features=128, bias=True)
      (activation): Tanh()
    )
  )
  (mlm_proj): Linear(in_features=128, out_features=28996, bias=True)
  (post_encode_proj): Linear(in_features=128, out_features=128, bias=True)
)

